import json
import re
import os
import sys
from typing import Dict, Any, Optional

def handler(event: dict, context) -> dict:
    '''–ü–∞—Ä—Å–µ—Ä –¥–∞–Ω–Ω—ã—Ö —Å Avito –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –æ–±—ä—è–≤–ª–µ–Ω–∏–π –≤ –∫–∞—Ç–∞–ª–æ–≥. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ø–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏—è –∏–ª–∏ –≤—Å–µ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è.'''
    
    method = event.get('httpMethod', 'GET')
    
    if method == 'OPTIONS':
        return {
            'statusCode': 200,
            'headers': {
                'Access-Control-Allow-Origin': '*',
                'Access-Control-Allow-Methods': 'GET, POST, OPTIONS',
                'Access-Control-Allow-Headers': 'Content-Type'
            },
            'body': '',
            'isBase64Encoded': False
        }
    
    if method != 'GET':
        return {
            'statusCode': 405,
            'headers': {
                'Content-Type': 'application/json',
                'Access-Control-Allow-Origin': '*'
            },
            'body': json.dumps({'error': 'Method not allowed'}),
            'isBase64Encoded': False
        }
    
    params = event.get('queryStringParameters', {}) or {}
    avito_url = params.get('url', '')
    parse_profile = params.get('profile', 'false').lower() == 'true'
    
    print(f'[ENTRY] URL: {avito_url}, profile: {parse_profile}', flush=True)
    sys.stdout.flush()
    
    if not avito_url:
        return {
            'statusCode': 400,
            'headers': {
                'Content-Type': 'application/json',
                'Access-Control-Allow-Origin': '*'
            },
            'body': json.dumps({'error': 'Missing url parameter'}),
            'isBase64Encoded': False
        }
    
    # –ï—Å–ª–∏ –Ω—É–∂–µ–Ω –ø–∞—Ä—Å–∏–Ω–≥ –ø—Ä–æ—Ñ–∏–ª—è
    if parse_profile:
        import requests
        from bs4 import BeautifulSoup
        
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            }
            
            print('[PROFILE] Fetching page...', flush=True)
            sys.stdout.flush()
            
            response = requests.get(avito_url, headers=headers, timeout=15)
            response.raise_for_status()
            
            print(f'[PROFILE] Status: {response.status_code}, Content length: {len(response.text)}', flush=True)
            sys.stdout.flush()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # Debug: —Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫–∏–µ data-marker –µ—Å—Ç—å –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
            all_markers = soup.find_all(attrs={'data-marker': True})
            marker_types = set([elem.get('data-marker', '') for elem in all_markers[:50]])
            print(f'[PROFILE] Found data-markers: {list(marker_types)[:10]}', flush=True)
            sys.stdout.flush()
            
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–π
            items = soup.find_all('div', {'data-marker': 'item'})
            
            if not items:
                # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Å–µ–ª–µ–∫—Ç–æ—Ä
                items = soup.select('[data-marker="item"]')
            
            # –ï—Å–ª–∏ –≤—Å—ë –µ—â—ë –Ω–µ –Ω–∞—à–ª–∏ - –∏—â–µ–º –ø–æ –¥—Ä—É–≥–∏–º –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º
            if not items:
                # –ò—â–µ–º –∫–∞—Ä—Ç–æ—á–∫–∏ –æ–±—ä—è–≤–ª–µ–Ω–∏–π –ø–æ –∫–ª–∞—Å—Å–∞–º
                items = soup.find_all('div', class_=re.compile(r'item-.*card'))
                print(f'[PROFILE] Trying class pattern, found: {len(items)}', flush=True)
            
            if not items:
                # –ò—â–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏—è –Ω–∞–ø—Ä—è–º—É—é
                links = soup.find_all('a', href=re.compile(r'/(dom|zemelnye|kvartiry|kommerchesk)_\d+'))
                print(f'[PROFILE] Trying direct links, found: {len(links)}', flush=True)
                # –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º —Å—Å—ã–ª–∫–∏ –≤ —Ñ–µ–π–∫–æ–≤—ã–µ items –¥–ª—è –µ–¥–∏–Ω–æ–æ–±—Ä–∞–∑–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                items = links
            
            print(f'[PROFILE] Found {len(items)} items on page', flush=True)
            sys.stdout.flush()
            
            profile_items = []
            for idx, item in enumerate(items[:20]):
                try:
                    # –ï—Å–ª–∏ item - —ç—Ç–æ —É–∂–µ —Å—Å—ã–ª–∫–∞ (–∏–∑ —Ç—Ä–µ—Ç—å–µ–≥–æ –º–µ—Ç–æ–¥–∞ –ø–æ–∏—Å–∫–∞)
                    if item.name == 'a':
                        link_elem = item
                        item_href = link_elem.get('href', '')
                        item_url = 'https://www.avito.ru' + item_href if item_href.startswith('/') else item_href
                    else:
                        # –ò—â–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ –≤–Ω—É—Ç—Ä–∏ item
                        link_elem = item.find('a', {'itemprop': 'url'})
                        if not link_elem:
                            link_elem = item.find('a', href=re.compile(r'/(dom|zemelnye|kvartiry|kommerchesk)'))
                        
                        if not link_elem:
                            print(f'[PROFILE] Item {idx}: no link found', flush=True)
                            sys.stdout.flush()
                            continue
                        
                        item_href = link_elem.get('href', '')
                        item_url = 'https://www.avito.ru' + item_href if item_href.startswith('/') else item_href
                    
                    title = link_elem.get('title', '').strip()
                    if not title:
                        title_elem = item.find(['h3', 'h2'])
                        title = title_elem.get_text(strip=True) if title_elem else '–û–±—ä—è–≤–ª–µ–Ω–∏–µ'
                    
                    price_elem = item.find('meta', {'itemprop': 'price'})
                    if not price_elem:
                        price_elem = item.find('span', {'data-marker': 'item-price'})
                    
                    price = 0
                    if price_elem:
                        price_text = price_elem.get('content', '') or price_elem.get_text(strip=True)
                        price_text = re.sub(r'[^\d]', '', price_text)
                        price = int(price_text) if price_text else 0
                    
                    location_elem = item.find('div', {'data-marker': 'item-address'})
                    if not location_elem:
                        location_elem = item.find('span', string=re.compile(r'–°–µ–≤–∞—Å—Ç–æ–ø–æ–ª—å|–ö—Ä—ã–º'))
                    location = location_elem.get_text(strip=True) if location_elem else '–ö—Ä—ã–º'
                    
                    img_elem = item.find('img')
                    photo = img_elem.get('src', '') or img_elem.get('data-src', '') if img_elem else ''
                    
                    print(f'[PROFILE] Item {idx}: title={title[:30]}, price={price}, url={item_url[:50]}', flush=True)
                    sys.stdout.flush()
                    
                    if title and item_url and '_' in item_url:
                        profile_items.append({
                            'title': title,
                            'price': price,
                            'location': location,
                            'photo_url': photo,
                            'property_link': item_url,
                            'type': 'land'
                        })
                except Exception as e:
                    print(f'[PROFILE] Item {idx} error: {str(e)}', flush=True)
                    sys.stdout.flush()
                    continue
            
            print(f'[PROFILE] Returning {len(profile_items)} items', flush=True)
            sys.stdout.flush()
            
            return {
                'statusCode': 200,
                'headers': {
                    'Content-Type': 'application/json',
                    'Access-Control-Allow-Origin': '*'
                },
                'body': json.dumps({
                    'success': True,
                    'items': profile_items,
                    'count': len(profile_items)
                }, ensure_ascii=False),
                'isBase64Encoded': False
            }
            
        except Exception as e:
            error_msg = f'Profile parsing error: {str(e)}'
            print(f'[PROFILE ERROR] {error_msg}', flush=True)
            sys.stdout.flush()
            return {
                'statusCode': 500,
                'headers': {
                    'Content-Type': 'application/json',
                    'Access-Control-Allow-Origin': '*'
                },
                'body': json.dumps({
                    'success': False,
                    'error': error_msg
                }),
                'isBase64Encoded': False
            }
    
    # –ü–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏—è
    listing_id_match = re.search(r'_(\d+)$', avito_url)
    if not listing_id_match:
        return {
            'statusCode': 400,
            'headers': {
                'Content-Type': 'application/json',
                'Access-Control-Allow-Origin': '*'
            },
            'body': json.dumps({'error': 'Invalid Avito URL format'}),
            'isBase64Encoded': False
        }
    
    listing_id = listing_id_match.group(1)
    
    # Mock data based on the Avito listing from Sevastopol
    # In production, this would use a web scraping library or Avito API
    property_data = {
        'title': '–£—á–∞—Å—Ç–æ–∫ 14,6 —Å–æ—Ç. (–°–ù–¢, –î–ù–ü)',
        'price': 10400000,
        'location': '–°–µ–≤–∞—Å—Ç–æ–ø–æ–ª—å, –ë–∞–ª–∞–∫–ª–∞–≤—Å–∫–∏–π —Ä-–Ω, –§–∏–æ–ª–µ–Ω—Ç',
        'land_area': 14.6,
        'type': 'land',
        'description': '''–ü—Ä–æ–¥–∞—é –∑–µ–º–µ–ª—å–Ω—ã–π —É—á–∞—Å—Ç–æ–∫ –Ω–∞ –§–∏–æ–ª–µ–Ω—Çe "–¢CH ¬´–°–æ—é–∑" —É—áa—Å—Ç–æ–∫ ‚Ññ 283

üìç –†–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ:
‚Ä¢ –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ —Ü–µ–Ω—Ç—Ä–∞: 12 –∫–º
‚Ä¢ –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ –º–æ—Ä—è: 1 –∫–º
‚Ä¢ –†–∞–π–æ–Ω: –ë–∞–ª–∞–∫–ª–∞–≤—Å–∫–∏–π, –§–∏–æ–ª–µ–Ω—Ç

üìê –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —É—á–∞—Å—Ç–∫–∞:
‚Ä¢ –ü–ª–æ—â–∞–¥—å: 14,6 —Å–æ—Ç–æ–∫ (1460 –º¬≤)
‚Ä¢ –ö–∞–¥–∞—Å—Ç—Ä–æ–≤—ã–µ –Ω–æ–º–µ—Ä–∞: 91:01:005018:128 (1326 –º¬≤) –∏ 91:01:005018:800 (147 –º¬≤)
‚Ä¢ –†–µ–ª—å–µ—Ñ: —Ä–æ–≤–Ω—ã–π
‚Ä¢ –ù–∞ —É—á–∞—Å—Ç–∫–µ —á–µ—Ä–Ω–æ–≤–∞—è –∫–æ—Ä–æ–±–∫–∞ –¥–æ–º–∞ 100 –º¬≤

‚ö° –ö–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏:
‚Ä¢ –≠–ª–µ–∫—Ç—Ä–∏—á–µ—Å—Ç–≤–æ –∏ –≤–æ–¥–∞ –ø–æ –≥—Ä–∞–Ω–∏—Ü–µ —É—á–∞—Å—Ç–∫–∞
‚Ä¢ –í–æ–∑–º–æ–∂–Ω–æ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –≥–∞–∑–∞
‚Ä¢ –ö—Ä—É–≥–ª–æ–≥–æ–¥–∏—á–Ω—ã–µ —Å–æ—Å–µ–¥–∏
‚Ä¢ –£–¥–æ–±–Ω—ã–µ –ø–æ–¥—ä–µ–∑–¥–Ω—ã–µ –ø—É—Ç–∏
‚Ä¢ –†–∞–∑–≤–∏—Ç–∞—è –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞

üìã –î–æ–∫—É–º–µ–Ω—Ç—ã:
‚Ä¢ –ì–æ—Ç–æ–≤ –∫ —Å–¥–µ–ª–∫–µ
‚Ä¢ –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º –†–§
‚Ä¢ –ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–∏–∫

–ò–¥–µ–∞–ª—å–Ω–æ –¥–ª—è —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–∞ –¥–æ–º–∞ –∏–ª–∏ –¥–∞—á–∏ –≤ –∂–∏–≤–æ–ø–∏—Å–Ω–æ–º —Ä–∞–π–æ–Ω–µ —Ä—è–¥–æ–º —Å –º–æ—Ä–µ–º!''',
        'photos': [
            'https://images.unsplash.com/photo-1500382017468-9049fed747ef?w=800',
            'https://images.unsplash.com/photo-1464146072230-91cabc968266?w=800',
            'https://images.unsplash.com/photo-1441974231531-c6227db76b6e?w=800'
        ],
        'property_link': avito_url,
        'phone': '+7 (978) 123-45-67',
        'features': [
            '–≠–ª–µ–∫—Ç—Ä–∏—á–µ—Å—Ç–≤–æ –ø–æ –≥—Ä–∞–Ω–∏—Ü–µ',
            '–í–æ–¥–∞ –ø–æ –≥—Ä–∞–Ω–∏—Ü–µ',
            '–í–æ–∑–º–æ–∂–Ω–æ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –≥–∞–∑–∞',
            '–†–æ–≤–Ω—ã–π —Ä–µ–ª—å–µ—Ñ',
            '–ß–µ—Ä–Ω–æ–≤–∞—è –∫–æ—Ä–æ–±–∫–∞ –¥–æ–º–∞ 100 –º¬≤',
            '1 –∫–º –¥–æ –º–æ—Ä—è',
            '–†–∞–∑–≤–∏—Ç–∞—è –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞'
        ]
    }
    
    return {
        'statusCode': 200,
        'headers': {
            'Content-Type': 'application/json',
            'Access-Control-Allow-Origin': '*'
        },
        'body': json.dumps({
            'success': True,
            'data': property_data
        }, ensure_ascii=False),
        'isBase64Encoded': False
    }